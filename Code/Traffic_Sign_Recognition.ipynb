{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IS2Jk5SFZCz2"
   },
   "source": [
    "### Import Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkJU7tY6iAhH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time as time\n",
    "\n",
    "import numpy as np # Optimizing matrix operations\n",
    "import random\n",
    "np.random.seed(105111) # to generate same random number all the time\n",
    "import matplotlib.pyplot as plt # Data Visualization\n",
    "import matplotlib.gridspec as gridspec\n",
    "import math # Math module to deal with math operations \n",
    "%matplotlib inline # To Present the images on the screen itself\n",
    "\n",
    "from PIL import Image # Used to open image content into an array\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd # data Manipulation\n",
    "from sklearn.metrics import accuracy_score # Finding accuracy of the trained model\n",
    "from matplotlib import pyplot\n",
    "import skimage.morphology as morp\n",
    "from skimage.filters import rank\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten # Layers included in the model architecture\n",
    "from keras.layers import Dropout # Regularize our model\n",
    "from keras.layers.normalization import BatchNormalization # Normalize the data\n",
    "from keras import regularizers # new! \n",
    "from keras.optimizers import SGD # Optimizer\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D # Different layers in CNN\n",
    "from keras.callbacks import ModelCheckpoint # For saving the best weights wrt validation erro\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWNdhADBZJlZ"
   },
   "source": [
    "### Unzip the Dataset Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVmasgK9yBKK",
    "outputId": "9088a387-cbc7-45f4-be8c-fccfe4578c01"
   },
   "outputs": [],
   "source": [
    "!wget https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip\n",
    "!unzip -q traffic-signs-data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJrGgv7FZPNA"
   },
   "source": [
    "### Read the Dataset in separate subsets\n",
    "Download the dataset from [here](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip). This is a pickled dataset in which we've already resized the images to 32x32.\n",
    "We already have three .p files of 32x32 resized images:\n",
    "train.p: The training set.\n",
    "test.p: The testing set.\n",
    "valid.p: The validation set.\n",
    "We will use Python pickle to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xT_DWKnVlxN"
   },
   "outputs": [],
   "source": [
    "training_file = \"/content/train.p\"\n",
    "testing_file = \"/content/test.p\"\n",
    "validation_file = \"/content/valid.p\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-oe0pslZZyD"
   },
   "source": [
    "### Load the Separate Subsets of the Initial Dataset\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "1. 'features' is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "2. 'labels' is a 1D array containing the label/class id of the traffic sign. The file signnames.csv contains id -> name mappings for each id.\n",
    "3. 'sizes' is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "4. 'coords' is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image.\n",
    "\n",
    "The code snippets below will provide a basic summary of the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7jjWvBtWdF4"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(training_file, mode='rb') as f:  # Training Dataset\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:  # Testing Dataset\n",
    "    test = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:  # Validation Dataset\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels'] # Separate features and labels for training dataset\n",
    "X_test, y_test = test['features'], test['labels'] # Separate features and labels for testing dataset\n",
    "X_valid , y_valid = valid['features'], valid['labels'] # Separate features and labels for Validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXmzbocAZi3E"
   },
   "source": [
    "### Understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2x-EWITWh4c",
    "outputId": "f52dcc26-65b1-4229-962c-34185f190221"
   },
   "outputs": [],
   "source": [
    "print(\"Training Set:\", len(X_train)) # Length of training dataset\n",
    "print(\"Test Set:\", len(y_test)) # Length of testing dataset\n",
    "print(\"Validation Set:\", len(X_valid))  # Length of validation dataset\n",
    "print(\"Image Dimensions:\", np.shape(X_train[1]))  # Dimension of the images in the dataset\n",
    "print(\"Number of classes:\", len(np.unique(y_train))) # Number of classes/possible outputs for images\n",
    "n_classes = len(np.unique(y_train)) # Store the number of classes in n_classes variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHw3LRMDpNBZ"
   },
   "source": [
    "### Use matplotlib to plot sample images from each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAf5gAxrpYqB"
   },
   "outputs": [],
   "source": [
    "# And finally, we will use numpy to plot a histogram of the count of images in each unique class.\n",
    "def histogram_plot(dataset, label):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the input data.\n",
    "        Parameters:\n",
    "            dataset: Input data to be plotted as a histogram.\n",
    "            lanel: A string to be used as a label for the histogram.\n",
    "    \"\"\"\n",
    "    hist, bins = np.histogram(dataset, bins=n_classes)\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel(\"Image count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "POALaPfRpgYC",
    "outputId": "cef40e70-fc63-4643-963c-8aba6f91530b"
   },
   "outputs": [],
   "source": [
    "# Plotting histograms of the count of each sign\n",
    "histogram_plot(y_train, \"Training examples\")\n",
    "histogram_plot(y_test, \"Testing examples\")\n",
    "histogram_plot(y_valid, \"Validation examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6UI-zHgZpC6"
   },
   "source": [
    "### Basic Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_xlQfIwpObo1",
    "outputId": "19afc279-9e0f-437a-9d1a-b695167f8fc1"
   },
   "outputs": [],
   "source": [
    "# Checking for Class Bias \n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts = True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "pyplot.bar( np.arange( 43 ), counts_elements, align='center',color='red' )\n",
    "pyplot.xlabel('Class Numbers for different classes')\n",
    "pyplot.ylabel('Number of Training data for that specific class')\n",
    "pyplot.xlim([-1, 43])\n",
    "\n",
    "pyplot.show()\n",
    "\n",
    "print(\" \")\n",
    "print(\"We can definitely see class bias issue as certain classes are under represented\")\n",
    "\n",
    "# Print some images from the dataset\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Traffic Sign Images\")\n",
    "fig, axs = plt.subplots(8,5, figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(40):\n",
    "    index = random.randint(0, len(X_train))\n",
    "    image = X_train[index]\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].set_title(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55RXkzzQZvza"
   },
   "source": [
    "### **Model Testing without any preprocessing -**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JugUc3LWZ2kJ"
   },
   "source": [
    "### Establishing Baseline Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXjdi2b8XADQ"
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization \n",
    "\n",
    "model = Sequential() # Gives a blank box as the output(Load the model) and we use further this to add the fully connected layers in it\n",
    "model.add(Dense(128, activation='relu', input_shape=(32*32*3,))) # Input layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) # 50% neurons are dropped\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(n_classes, activation='softmax')) # Apply softmax activation at the Final layer to find probability distribution of differ classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QylF6tx8sCnp"
   },
   "source": [
    "### Analyzing model Summary and Compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnCi_zPkXQLs",
    "outputId": "ca33e527-f732-4a3b-ad21-c424a55a1094"
   },
   "outputs": [],
   "source": [
    "model.summary() \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnKchiAYsMCA"
   },
   "source": [
    "### Make train and validation dataset for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_1vlXF9XXqZ"
   },
   "outputs": [],
   "source": [
    "X_train_baseline = X_train.reshape(len(X_train), 32*32*3).astype('float32')\n",
    "X_valid_baseline = X_valid.reshape(len(X_valid), 32*32*3).astype('float32')\n",
    "# From the keras.utils package, we use to_categorical method to convert the labels present in y_train and y_test into one-hot encoding.\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "y_train_baseline = to_categorical(y_train, n_classes)\n",
    "y_valid_baseline = to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5sifSbPsNQi"
   },
   "source": [
    "### Training or fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zMKt7NkXcG4",
    "outputId": "f6d4beb3-bac9-42cd-95af-f59c1edfd80d"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_baseline, y_train_baseline, batch_size=128, epochs=10\n",
    ", verbose=1, validation_data=(X_valid_baseline, y_valid_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYkEiIC9scm2"
   },
   "source": [
    "### Make Testing dataset for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9xFRkVJc17l"
   },
   "outputs": [],
   "source": [
    "X_test_baseline = X_test.reshape(len(X_test), 32*32*3).astype('float32') # reshaping the images according to our images in training dataset\n",
    "y_test_baseline = to_categorical(y_test, n_classes) # actual output for all the images to evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvjMqdDhsi2n"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWvsqrCNX70p",
    "outputId": "9a4c0a37-4f50-4b16-a512-e83c3eefd4c9"
   },
   "outputs": [],
   "source": [
    "Prediction_test = model.evaluate(X_test_baseline, y_test_baseline, verbose=0)\n",
    "print(\"Results for Dense fully connected network (baseline model) on the test data \\n\")\n",
    "print(\"%s- %.3f\" % (model.metrics_names[0], Prediction_test[0]))\n",
    "print(\"%s- %.3f\" % (model.metrics_names[1], Prediction_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4vKxHR7Xp3D"
   },
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGeZaQXSYwOT"
   },
   "outputs": [],
   "source": [
    "# Function to augment the images (make more images other than given images in the dataset)\n",
    "def data_augment(image):\n",
    "    rows= image.shape[0]\n",
    "    cols = image.shape[1]\n",
    "    \n",
    "    # New Image formed with the help of rotation\n",
    "    M_rot = cv2.getRotationMatrix2D((cols/2,rows/2),10,1)\n",
    "    \n",
    "    # New Image formed with the help of Translation\n",
    "    M_trans = np.float32([[1,0,3],[0,1,6]])\n",
    "    \n",
    "    \n",
    "    img = cv2.warpAffine(image,M_rot,(cols,rows)) # rotation\n",
    "    img = cv2.warpAffine(img,M_trans,(cols,rows)) # translation\n",
    "    \n",
    "    # New Image formed with the help of Bilateral filtering\n",
    "    img = cv2.bilateralFilter(img,9,75,75)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pznb5nKDtD5A"
   },
   "source": [
    "### Increase training set by Data augmentation and making all class size similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbkARjEFY4gL"
   },
   "outputs": [],
   "source": [
    "classes = 43\n",
    "\n",
    "X_train_final = X_train\n",
    "y_train_final = y_train\n",
    "X_aug_1 = []\n",
    "Y_aug_1 = []\n",
    "\n",
    "for i in range(0,classes):\n",
    "    \n",
    "    class_records = np.where(y_train==i)[0].size\n",
    "    max_records = 4000\n",
    "    if class_records != max_records:\n",
    "        ovr_sample = max_records - class_records\n",
    "        samples = X_train[np.where(y_train==i)[0]]\n",
    "        X_aug = []\n",
    "        Y_aug = [i] * ovr_sample\n",
    "        \n",
    "        for x in range(ovr_sample):\n",
    "            img = samples[x % class_records]\n",
    "            trans_img = data_augment(img)\n",
    "            X_aug.append(trans_img)\n",
    "            \n",
    "        X_train_final = np.concatenate((X_train_final, X_aug), axis=0)\n",
    "        y_train_final = np.concatenate((y_train_final, Y_aug)) \n",
    "        \n",
    "        Y_aug_1 = Y_aug_1 + Y_aug\n",
    "        X_aug_1 = X_aug_1 + X_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3KHHRXKtLRa"
   },
   "source": [
    "### Check class bias after augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "pzbiZbXzY7df",
    "outputId": "89285f31-fd00-4e2e-b7e2-e11c1515b12e"
   },
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train_final, return_counts = True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "pyplot.bar( np.arange( 43 ), counts_elements, align='center',color='green' )\n",
    "pyplot.xlabel('Class')\n",
    "pyplot.ylabel('No of Training data')\n",
    "pyplot.xlim([-1, 43])\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svxLDJjZtP1C"
   },
   "source": [
    "### Shape of the datasets after data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Y4-v6-WZ-xG",
    "outputId": "d09faa87-4d4a-4ee0-fd41-5412ddbfd82a"
   },
   "outputs": [],
   "source": [
    "print(len(X_train)) # features of Training dataset length before augmentation\n",
    "print(len(X_train_final)) # features of Training dataset length after augmentation\n",
    "print(len(y_train)) # labels of Training dataset length before augmentation\n",
    "print(len(y_train_final)) # labels of Training dataset length after augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRdu1DJZtVUK"
   },
   "source": [
    "### View images after data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "hg3MtHDHaCel",
    "outputId": "c72d3e8f-3f73-4367-bd4e-9fcd64d5b8f1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Present some of the images to understand our applied transformations\")\n",
    "fig, axs = plt.subplots(8,5, figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(40):\n",
    "    index = random.randint(0, len(X_aug_1))\n",
    "    image = X_aug_1[index]\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].set_title(Y_aug_1[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiMVG56QtaYz"
   },
   "source": [
    "### Model Testing after Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4qHWwc9aFNr"
   },
   "outputs": [],
   "source": [
    "X_train_aug = X_train_final.reshape(len(X_train_final), 32*32*3).astype('float32')\n",
    "X_valid_aug = X_valid.reshape(len(X_valid), 32*32*3).astype('float32')\n",
    "y_train_aug = to_categorical(y_train_final, n_classes)\n",
    "y_valid_aug = to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEanmSYlaINJ"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "filepath=\"German_Traffic_DenseNetworkModel_AfterAugmentation.h5\"\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJXAlOH9aNBR",
    "outputId": "9d54aac9-a295-43b1-c90e-5de091ade0d2"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_aug, y_train_aug, batch_size=128, epochs=50, verbose=1,callbacks=callbacks_list,validation_data=(X_valid_aug, y_valid_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWa-RZasaWWq"
   },
   "outputs": [],
   "source": [
    "X_test_aug = X_test.reshape(len(X_test), 32*32*3).astype('float32')\n",
    "y_test_aug = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMGpJ_VXccxb"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"German_Traffic_DenseNetworkModel_AfterAugmentation.h5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nFD3P8bce0c",
    "outputId": "b4f314a3-471b-4b66-87a7-347a28f6978f"
   },
   "outputs": [],
   "source": [
    "Pred = model.evaluate(X_test_aug, y_test_aug, verbose=0)\n",
    "print(\"Dense fully connected network results on the test data - After Data Augmentation \")\n",
    "print(\" \")\n",
    "print(\"%s- %.2f\" % (model.metrics_names[0], Pred[0]))\n",
    "print(\"%s- %.2f\" % (model.metrics_names[1], Pred[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLlgzjacsm-d"
   },
   "source": [
    "### Data preprocessing \n",
    "In this step, we will apply several preprocessing steps to the input images to achieve the best possible results.\n",
    "We will use the following preprocessing techniques:\n",
    "Shuffling,\n",
    "Grayscaling,\n",
    "Local Histogram Equalization,\n",
    "Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J1NDQ6CYF87"
   },
   "source": [
    "### Shuffling of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiSMH5vjqLau"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train_aug, y_train_aug = shuffle(X_train_aug, y_train_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ1eOStifv8R"
   },
   "source": [
    "### Convert the Images into Grey Scale instead of RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "3AsxWPR-da6T",
    "outputId": "d0e5efa7-0956-47a5-9804-c95037cadfbf"
   },
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    \n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "gray_images_data = list(map(gray_scale, X_train_final))\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Present few images to familiarize with the dataset\")\n",
    "fig, axs = plt.subplots(8,5, figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(40):\n",
    "    index = np.random.randint(0, len(gray_images_data))\n",
    "    image = gray_images_data[index]\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image,cmap='gray')\n",
    "    axs[i].set_title(y_train_final[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-kIqKxQf6DI"
   },
   "source": [
    "### Local Histogram Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "4qsqpoh0dhZ6",
    "outputId": "c6f5e634-f988-4491-8a61-cdecc71f81a9"
   },
   "outputs": [],
   "source": [
    "import skimage.morphology as morp\n",
    "from skimage.filters import rank\n",
    "\n",
    "def local_histo_equalize(image):\n",
    "    \n",
    "    kernel = morp.disk(30)\n",
    "    img_local = rank.equalize(image, selem=kernel)\n",
    "    return img_local\n",
    "\n",
    "\n",
    "local_histo = np.array(list(map(local_histo_equalize, gray_images_data)))\n",
    "%matplotlib inline\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Let's view few images after applying local histogram equilization and Gray scaling\")\n",
    "fig, axs = plt.subplots(8,5, figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i in range(40):\n",
    "    index = np.random.randint(0, len(local_histo))\n",
    "    image = local_histo[index]\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image,cmap = 'gray')\n",
    "    axs[i].set_title(y_train_final[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbaiKagtgD77"
   },
   "source": [
    "### Function to preprocess the data according to above data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20taVP7QdlCN"
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    gray_images = list(map(gray_scale, data))\n",
    "    equalized_images = list(map(local_histo_equalize, gray_images))\n",
    "    n_training = data.shape\n",
    "    normalized_images = np.zeros((n_training[0], n_training[1], n_training[2]))\n",
    "    for i, img in enumerate(equalized_images): # Normalization step \n",
    "        normalized_images[i] = np.divide(img,255)\n",
    "    normalized_images = normalized_images[..., None]\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id6n013DgPM_"
   },
   "source": [
    "### Apply Data preprocessing steps to the training and the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1weIw8X2dnwR"
   },
   "outputs": [],
   "source": [
    "X_train_preprocessed = preprocess(X_train_final)\n",
    "X_valid_preprocessed = preprocess(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5cME2Iydqd1"
   },
   "outputs": [],
   "source": [
    "X_train_preprocessed_dn = X_train_preprocessed.reshape(len(X_train_preprocessed), 32*32*1).astype('float32')\n",
    "X_valid_preprocessed_dn = X_valid_preprocessed.reshape(len(X_valid_preprocessed), 32*32*1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97c7KvdaduqJ"
   },
   "outputs": [],
   "source": [
    "y_train_final_dn = to_categorical(y_train_final, n_classes)\n",
    "y_valid_final_dn = to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEHTeBnkgUgj"
   },
   "source": [
    "### Check the shape of the datasets after all preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhZQ1k9Tdx9r",
    "outputId": "049d5caf-0e39-496f-f473-15d76769f7d7"
   },
   "outputs": [],
   "source": [
    "print(X_train_preprocessed_dn.shape)\n",
    "print(X_valid_preprocessed_dn.shape)\n",
    "print(y_train_final_dn.shape)\n",
    "print(y_valid_final_dn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLNLc4TlgY5X"
   },
   "source": [
    "### Compile and fit the model after preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE9CUIKTgdEe"
   },
   "source": [
    "### Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htYQoaM-d1sk"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(32*32*1,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnbil1_6d33A"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Model Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoMraHGYgimp"
   },
   "source": [
    "### Save model with Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_aYpIx_d4bA"
   },
   "outputs": [],
   "source": [
    "filepath=\"German_Traffic_DenseNetworkModel_final.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9diJvmSd7Ir",
    "outputId": "8e4f1792-bc45-4b13-9165-f05f5d4559a8"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_preprocessed_dn, y_train_final_dn, batch_size=128, epochs=50, verbose=1,callbacks=callbacks_list,validation_data=(X_valid_preprocessed_dn, y_valid_final_dn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wph1c2Z_go0D"
   },
   "source": [
    "### Prepare test data for final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmjULTJ4eFoH"
   },
   "outputs": [],
   "source": [
    "# Prepare the Test data with all the preprocessing\n",
    "\n",
    "X_test_preprocessed = preprocess(X_test)\n",
    "X_test_preprocessed_dn = X_test_preprocessed.reshape(len(X_test_preprocessed), 32*32*1).astype('float32')\n",
    "y_test_final_dn = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8bh7ETJgwqJ"
   },
   "source": [
    "### Load the best model from the validation data results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "kIlbx5zpeLVO",
    "outputId": "f3ac2a73-6a1b-457d-b5e8-6fd160c8b0a3"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.load_weights(\"German_Traffic_DenseNetworkModel_final.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hG0DfTieNqT"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcGWf6NeeOOp",
    "outputId": "01e67517-2b87-40ae-8981-f245eb2745cc"
   },
   "outputs": [],
   "source": [
    "Pred = model.evaluate(X_test_preprocessed_dn, y_test_final_dn, verbose=0)\n",
    "print(\"Dense fully connected network results on the test data\")\n",
    "print(\" \")\n",
    "print(\"%s- %.2f%%\" % (model.metrics_names[0], Pred[0]*100))\n",
    "print(\"%s- %.2f%%\" % (model.metrics_names[1], Pred[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sJ__-jug06T"
   },
   "source": [
    "### Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxR7CrEmeQsG"
   },
   "outputs": [],
   "source": [
    "# Prepare data for Conv nets\n",
    "X_train_preprocessed_cn = X_train_preprocessed.reshape(len(X_train_preprocessed), 32,32,1).astype('float32')\n",
    "X_valid_preprocessed_cn = X_valid_preprocessed.reshape(len(X_valid_preprocessed), 32,32,1).astype('float32')\n",
    "X_test_preprocessed_cn = X_test_preprocessed.reshape(len(X_test_preprocessed), 32,32,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da36KFUHeQuN"
   },
   "outputs": [],
   "source": [
    "y_train_final_cn = to_categorical(y_train_final, n_classes)\n",
    "y_valid_final_cn = to_categorical(y_valid, n_classes)\n",
    "y_test_final_cn = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6iQca-XeU5y"
   },
   "outputs": [],
   "source": [
    "model_conv = Sequential()\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "## If You preprocessed with gray scaling and local histogram equivalization then input_shape = (32,32,1) else (32,32,3)\n",
    "model_conv.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=(32, 32, 1)))\n",
    "model_conv.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model_conv.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model_conv.add(Dropout(0.25))\n",
    "model_conv.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(128, activation='relu'))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHxTg3MCeQwl"
   },
   "outputs": [],
   "source": [
    "model_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDLcsKHueQzQ"
   },
   "outputs": [],
   "source": [
    "filepath=\"German_Traffic_ConvNetworkModel.h5\"\n",
    "checkpoint_conv = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_conv = [checkpoint_conv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZt_WKePkFy6",
    "outputId": "65a589de-7192-4006-e6a0-4d1b945e4294"
   },
   "outputs": [],
   "source": [
    "model_conv.fit(X_train_preprocessed_cn, y_train_final_cn, batch_size=128, epochs=3, verbose=1,callbacks=callbacks_list_conv,validation_data=(X_valid_preprocessed_cn, y_valid_final_cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8o4kLz5BedWq"
   },
   "outputs": [],
   "source": [
    "# model_conv.load_weights(\"German_Traffic_ConvNetworkModel.h5\")\n",
    "model_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AF80M58AekdW",
    "outputId": "981747e2-74c1-4975-85f1-f2ddeee03e9c"
   },
   "outputs": [],
   "source": [
    "Pred_conv = model_conv.evaluate(X_test_preprocessed_cn, y_test_final_cn, verbose=0)\n",
    "print(\"Dense fully connected network results on the test data\")\n",
    "print(\" \")\n",
    "print(\"%s- %.2f\" % (model.metrics_names[0], Pred_conv[0]))\n",
    "print(\"%s- %.2f\" % (model.metrics_names[1], Pred_conv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tensorflow.keras.models.load_model('Model\\German_Traffic_DenseNetworkModel_final.h5')\n",
    "loaded_model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Traffic_Sign_Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
